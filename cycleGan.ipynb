{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cycleGan",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvo-wQowbx-_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/horse2zebra.zip\n",
        "!unzip horse2zebra.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji_pCLa3h9Hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKVE-Cd2czl9",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCmcX0IYcNcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import random\n",
        "import itertools\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgm2RZmvcfMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
        "        \n",
        "class ReplayBuffer():\n",
        "    def __init__(self, max_size=50):\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data.data:\n",
        "            element = torch.unsqueeze(element, 0)\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                to_return.append(element)\n",
        "            else:\n",
        "                if random.uniform(0,1) > 0.5:\n",
        "                    i = random.randint(0, self.max_size-1)\n",
        "                    to_return.append(self.data[i].clone())\n",
        "                    self.data[i] = element\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return torch.tensor(torch.cat(to_return), dtype=torch.float32, device=device)\n",
        "      \n",
        "      \n",
        "class LambdaLR():\n",
        "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
        "        assert ((n_epochs - decay_start_epoch) > 0), \"Decay must start before the training session ends!\"\n",
        "        self.n_epochs = n_epochs\n",
        "        self.offset = offset\n",
        "        self.decay_start_epoch = decay_start_epoch\n",
        "\n",
        "    def step(self, epoch):\n",
        "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XIPgGlNecv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResnetGenerator(nn.Module):\n",
        "  def __init__(self, input_nc, output_nc, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False, n_blocks=6, padding_type='reflect'):\n",
        "    'Construct a Resnet-based generator'\n",
        "    super(ResnetGenerator, self).__init__()\n",
        "    use_bias = norm_layer == nn.InstanceNorm2d\n",
        "    \n",
        "    model = [nn.ReflectionPad2d(3),\n",
        "             nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n",
        "             norm_layer(ngf),\n",
        "             nn.ReLU(True)]\n",
        "    \n",
        "    n_downsampling = 2\n",
        "    \n",
        "    for i in range(0, n_downsampling):\n",
        "      mult = 2 ** i\n",
        "      model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
        "                      norm_layer(ngf * mult * 2),\n",
        "                      nn.ReLU(True)]\n",
        "      \n",
        "    mult = 2 ** n_downsampling\n",
        "    \n",
        "    for i in range(n_blocks):\n",
        "      model += [ResnetBlock(ngf * mult, padding_type=padding_type, norm_layer=norm_layer, use_dropout=use_dropout, use_bias=use_bias)]\n",
        "    \n",
        "    for i in range(0, n_downsampling):  \n",
        "      mult = 2 ** int(n_downsampling - i)\n",
        "      model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),  kernel_size=3, stride=2, padding=1, output_padding=1, bias=use_bias),\n",
        "                norm_layer(int(ngf * mult / 2)),\n",
        "                nn.ReLU(True)]\n",
        "      \n",
        "    model += [nn.ReflectionPad2d(3)]\n",
        "    model += [nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0)]\n",
        "    model += [nn.Tanh()]\n",
        "\n",
        "    self.model = nn.Sequential(*model)\n",
        "      \n",
        "  def forward(self, input):\n",
        "    return self.model(input)\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "  def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
        "    super(ResnetBlock, self).__init__()\n",
        "    conv_block = []\n",
        "    p = 0\n",
        "\n",
        "    if padding_type == 'reflect':\n",
        "      conv_block += [nn.ReflectionPad2d(1)]\n",
        "    elif padding_type == 'replicate':\n",
        "      conv_block += [nn.ReplicationPad2d(1)]\n",
        "    elif padding_type == 'zero':\n",
        "      p = 1\n",
        "    \n",
        "    conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim), nn.ReLU(True)]\n",
        "    \n",
        "    if use_dropout:\n",
        "      conv_block += [nn.Dropout(0.5)]\n",
        "    \n",
        "    p = 0\n",
        "    if padding_type == 'reflect':\n",
        "      conv_block += [nn.ReflectionPad2d(1)]\n",
        "    elif padding_type == 'replicate':\n",
        "      conv_block += [nn.ReplicationPad2d(1)]\n",
        "    elif padding_type == 'zero':\n",
        "      p = 1\n",
        "    \n",
        "    conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias), norm_layer(dim)]\n",
        "    \n",
        "    self.conv_block = nn.Sequential(*conv_block)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = x + self.conv_block(x)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfm0pqMdlY-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NLayerDiscriminator(nn.Module):\n",
        "  def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
        "    super(NLayerDiscriminator, self).__init__()\n",
        "    use_bias = norm_layer != nn.BatchNorm2d\n",
        "    kw = 4\n",
        "    padw = 1\n",
        "    \n",
        "    model = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
        "    nf_mult = 1\n",
        "    nf_mult_prev = 1\n",
        "    for n in range(1, n_layers):\n",
        "      nf_mult_prev = nf_mult\n",
        "      nf_mult = min(2 ** n, 8)\n",
        "      model += [nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
        "                norm_layer(ndf * nf_mult),\n",
        "                nn.LeakyReLU(0.2, True)]\n",
        "    nf_mult_prev = nf_mult\n",
        "    nf_mult = min(2 ** n_layers, 8)\n",
        "    model += [nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
        "              norm_layer(ndf * nf_mult),\n",
        "              nn.LeakyReLU(0.2, True)]\n",
        "    model += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]\n",
        "    self.model = nn.Sequential(*model)\n",
        "    \n",
        "  def forward(self, input):\n",
        "    return self.model(input)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViFWE2HehrYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GANLOSS(nn.Module):\n",
        "  def __init__(self, target_real_label = 1.0, target_fake_label = 0.0):\n",
        "    super(GANLOSS, self).__init__()\n",
        "    self.register_buffer('real_label', torch.tensor(target_real_label))\n",
        "    self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
        "    self.gan_mode = 'lsgan'\n",
        "    self.loss = nn.MSELoss()\n",
        "  \n",
        "  def get_target_tensor(self, prediction, target_is_real):\n",
        "    if (target_is_real):\n",
        "        target_tensor = self.real_label\n",
        "    else:\n",
        "        target_tensor = self.fake_label\n",
        "    return target_tensor.expand_as(prediction)\n",
        "  def __call__(self, prediction, target_is_real):\n",
        "    target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
        "    loss = self.loss(prediction, target_tensor)\n",
        "    return loss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9HQNIGFkdwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.utils.data as data\n",
        "from PIL import Image\n",
        "import os \n",
        "import os.path\n",
        "\n",
        "def make_dataset(dir):\n",
        "  images = []\n",
        "  for root, _, fnames in sorted(os.walk(dir)):\n",
        "    for fname in fnames:\n",
        "      path = os.path.join(root,fname)\n",
        "      images.append(path)\n",
        "  return images\n",
        "\n",
        "def loader(path):\n",
        "  return Image.open(path).convert(\"RGB\")\n",
        "\n",
        "class ImageLoader(data.Dataset):\n",
        "  def __init__(self, root, transform=None):\n",
        "    imgs = make_dataset(root)\n",
        "    \n",
        "    self.root = root\n",
        "    self.imgs = imgs\n",
        "    self.transform = transform\n",
        "    self.loader = loader\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    path = self.imgs[index]\n",
        "    img = self.loader(path)\n",
        "    if(self.transform != None):\n",
        "      img = self.tranform(img)\n",
        "    else:\n",
        "      return img\n",
        "  def __len__(self):\n",
        "    return len(self.imgs)\n",
        "     \n",
        "def set_requires_grad(nets, requires_grad = False):\n",
        "  if(not isinstance(nets, list)):\n",
        "    nets = [nets]\n",
        "  for net in nets:\n",
        "    if(net is not None):\n",
        "      for param in net.parameters():\n",
        "        param.requires_grad = requires_grad\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK8D6FS3oRNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterionGAN  = GANLOSS().to(device)\n",
        "criterionCycle = torch.nn.L1Loss()\n",
        "criterionIdt = torch.nn.L1Loss()\n",
        "netG_A2B = ResnetGenerator(3,3).to(device)\n",
        "netG_B2A = ResnetGenerator(3,3).to(device)\n",
        "netD_A = NLayerDiscriminator(3).to(device)\n",
        "netD_B = NLayerDiscriminator(3).to(device)\n",
        "\n",
        "netG_A2B.apply(weights_init_normal)\n",
        "netG_B2A.apply(weights_init_normal)\n",
        "netD_A.apply(weights_init_normal)\n",
        "netD_B.apply(weights_init_normal)\n",
        "\n",
        "\n",
        "n_epochs = 200\n",
        "epoch = 0\n",
        "decay_epoch = 100\n",
        "\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "criterion_identity = torch.nn.L1Loss()\n",
        "\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()\n",
        "\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()), lr=0.0001)\n",
        "optimizer_D_A  = torch.optim.Adam(netD_A.parameters(), lr=0.0001)\n",
        "optimizer_D_B  = torch.optim.Adam(netD_B.parameters(), lr=0.0001)\n",
        "\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
        "\n",
        "\n",
        "realA_loader = ImageLoader('./horse2zebra/trainA')\n",
        "realB_loader = ImageLoader('./horse2zebra/trainB')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_tozJzBiR9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "loss_D_B = None\n",
        "loss_D_A = None\n",
        "loss_G = None\n",
        "\n",
        "target_real = torch.ones([1]).cuda()\n",
        "target_fake = torch.zeros([1]).cuda()\n",
        "\n",
        "\n",
        "for epoch in range(epoch, n_epochs): \n",
        "\n",
        "  for i, (real_A, real_B) in enumerate(zip(realA_loader, realB_loader)):\n",
        "    \n",
        "    real_A = torch.tensor(np.array(real_A).reshape((-1, 3, 256, 256)), dtype=torch.float32, device=device)\n",
        "    real_B = torch.tensor(np.array(real_B).reshape((-1, 3, 256, 256)), dtype=torch.float32, device=device)\n",
        "    optimizer_G.zero_grad()\n",
        "  \n",
        "    same_A = netG_B2A(real_A)\n",
        "    loss_identity_A = criterion_identity(same_A, real_A) * 5.0\n",
        "    same_B = netG_A2B(real_B)\n",
        "    loss_identity_B = criterion_identity(same_B, real_B) * 5.0\n",
        "  \n",
        "    \n",
        "  \n",
        "    fake_A = netG_B2A(real_B)\n",
        "    pred_fake = netD_B(fake_A)\n",
        "    loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
        "  \n",
        "    fake_B = netG_A2B(real_A)\n",
        "    pred_fake = netD_A(fake_B)\n",
        "    loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
        "    \n",
        "    recovered_A = netG_B2A(fake_B)\n",
        "    recovered_B = netG_A2B(fake_A)\n",
        "    \n",
        "    loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*10.0\n",
        "    loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*10.0\n",
        "    loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
        "    loss_G.backward()\n",
        "    optimizer_G.step()\n",
        "    \n",
        "    optimizer_D_A.zero_grad()\n",
        "    pred_real = netD_A(real_A)\n",
        "    loss_D_real = criterion_GAN(pred_real, target_real)  \n",
        "    fake_A = fake_A_buffer.push_and_pop(fake_A)\n",
        "    pred_fake = netD_A(fake_A.detach())\n",
        "    loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
        "    loss_D_A = (loss_D_real + loss_D_fake)*0.5\n",
        "    loss_D_A.backward()\n",
        "    optimizer_D_A.step()\n",
        "        \n",
        "      \n",
        "    optimizer_D_B.zero_grad()\n",
        "    pred_real = netD_B(real_B)\n",
        "    loss_D_real = criterion_GAN(pred_real, target_real)        \n",
        "    fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
        "    pred_fake = netD_B(fake_B.detach())\n",
        "    loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
        "    loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
        "    loss_D_B.backward()\n",
        "    optimizer_D_B.step()\n",
        "  \n",
        "  lr_scheduler_G.step()\n",
        "  lr_scheduler_D_A.step()\n",
        "  lr_scheduler_D_B.step()\n",
        "    \n",
        "  \n",
        "  print(\"{}:  {}, {} :: {}\".format(epoch + 1, loss_D_B, loss_D_A, loss_G))  \n",
        "\n",
        "\n",
        "  torch.save(netG_A2B,\"genA.pb\")\n",
        "  torch.save(netG_B2A,\"genB.pb\")\n",
        "\n",
        "  torch.save(netD_A,\"disA.pb\")\n",
        "  torch.save(netD_B,\"disB.pb\")\n",
        "\n",
        "\n",
        "  model_file = drive.CreateFile({'title' : 'genA.pb'})\n",
        "  model_file.SetContentFile('genA.pb')\n",
        "  model_file.Upload()\n",
        "  drive.CreateFile({'id': model_file.get('id')})\n",
        "\n",
        "  model_file = drive.CreateFile({'title' : 'genB.pb'})\n",
        "  model_file.SetContentFile('genB.pb')\n",
        "  model_file.Upload()\n",
        "  drive.CreateFile({'id': model_file.get('id')})\n",
        "\n",
        "  model_file = drive.CreateFile({'title' : 'disA.pb'})\n",
        "  model_file.SetContentFile('disA.pb')\n",
        "  model_file.Upload()\n",
        "  drive.CreateFile({'id': model_file.get('id')})\n",
        "\n",
        "  model_file = drive.CreateFile({'title' : 'disB.pb'})\n",
        "  model_file.SetContentFile('disB.pb')\n",
        "  model_file.Upload()\n",
        "  drive.CreateFile({'id': model_file.get('id')})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc4d7nsBaTQp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KagoEFtUoFVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1SK8YwLkSmY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "real_A = realA_loader[0]\n",
        "real_B = realB_loader[0]\n",
        "\n",
        "a = fig.add_subplot(2,2,1)\n",
        "plt.imshow(real_A)\n",
        "\n",
        "a = fig.add_subplot(2,2,3)\n",
        "plt.imshow(real_B)\n",
        "\n",
        "\n",
        "real_A = torch.tensor(np.array(real_A).reshape((-1,3,256,256)), dtype=torch.float32, device=device)\n",
        "real_B = torch.tensor(np.array(real_B).reshape((-1,3,256,256)), dtype=torch.float32, device=device)\n",
        "\n",
        "fake_B = netG_A(real_A)\n",
        "fake_A = netG_B(real_B)\n",
        "fake_B = fake_B.cpu().detach().numpy().reshape((-1,256,256,3)).squeeze()\n",
        "fake_A = fake_A.cpu().detach().numpy().reshape((-1,256,256,3)).squeeze()\n",
        "\n",
        "fake_A.astype(np.uint8)\n",
        "fake_B.astype(np.uint8)\n",
        "\n",
        "a = fig.add_subplot(2,2,2)\n",
        "plt.imshow(fake_A)\n",
        "\n",
        "\n",
        "\n",
        "a = fig.add_subplot(2,2,4)\n",
        "plt.imshow(fake_B)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}